{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5876868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m20.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "503b5d35",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_full_repo_name' from 'huggingface_hub' (/home/mty/miniconda3/envs/py39/lib/python3.9/site-packages/huggingface_hub/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer,GenerationConfig\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForSeq2SeqLM,AutoModelForCausalLM\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/__init__.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     29\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     logging,\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     51\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/dependency_versions_check.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[1;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/utils/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# coding=utf-8\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_full_repo_name  \u001b[38;5;66;03m# for backward compatibility\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HF_HUB_DISABLE_TELEMETRY \u001b[38;5;28;01mas\u001b[39;00m DISABLE_TELEMETRY  \u001b[38;5;66;03m# for backward compatibility\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_full_repo_name' from 'huggingface_hub' (/home/mty/miniconda3/envs/py39/lib/python3.9/site-packages/huggingface_hub/__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer,GenerationConfig\n",
    "from transformers import AutoModelForSeq2SeqLM,AutoModelForCausalLM\n",
    "\n",
    "# import huggingface_hub\n",
    "import csv\n",
    "# import time\n",
    "# from multiprocessing.pool import ThreadPool\n",
    "# import requests\n",
    "# import os\n",
    "# import PIL.Image as Image\n",
    "# from io import BytesIO \n",
    "# import numpy as np\n",
    "from tqdm import tqdm\n",
    "# import shutil\n",
    "\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b682415",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES = 5\n",
    "device = \"cuda:0\"\n",
    "base_file = \"./data/eval_images_coarse-grained.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "858216d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Gustavosta/MagicPrompt-Stable-Diffusion\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Gustavosta/MagicPrompt-Stable-Diffusion\")\n",
    "gpt2_pipe = pipeline(\"text-generation\", model= model, tokenizer = tokenizer, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262123f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8192 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 1/8192 [00:00<1:32:38,  1.47it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 2/8192 [00:01<1:33:20,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 3/8192 [00:02<1:32:48,  1.47it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 4/8192 [00:02<1:30:39,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 5/8192 [00:03<1:31:34,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 6/8192 [00:03<1:15:16,  1.81it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 7/8192 [00:04<1:20:27,  1.70it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 8/8192 [00:05<1:23:43,  1.63it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 9/8192 [00:05<1:26:05,  1.58it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 10/8192 [00:06<1:27:28,  1.56it/s]/usr/local/lib/python3.9/dist-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 11/8192 [00:07<1:28:22,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 12/8192 [00:07<1:29:50,  1.52it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 13/8192 [00:08<1:30:25,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 14/8192 [00:09<1:31:12,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 15/8192 [00:09<1:32:08,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 16/8192 [00:10<1:32:07,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 17/8192 [00:11<1:32:03,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 18/8192 [00:11<1:31:57,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 19/8192 [00:12<1:31:52,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 20/8192 [00:13<1:31:55,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 21/8192 [00:13<1:24:25,  1.61it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 22/8192 [00:14<1:26:44,  1.57it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 23/8192 [00:14<1:28:43,  1.53it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 24/8192 [00:15<1:29:21,  1.52it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 25/8192 [00:16<1:30:00,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 26/8192 [00:16<1:30:17,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 27/8192 [00:17<1:28:12,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 28/8192 [00:18<1:29:29,  1.52it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 29/8192 [00:18<1:27:29,  1.56it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 30/8192 [00:19<1:28:14,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 31/8192 [00:20<1:28:43,  1.53it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 32/8192 [00:20<1:29:22,  1.52it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 33/8192 [00:21<1:29:46,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 34/8192 [00:21<1:08:16,  1.99it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 35/8192 [00:22<1:15:07,  1.81it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 36/8192 [00:23<1:20:58,  1.68it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 37/8192 [00:23<1:24:59,  1.60it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 38/8192 [00:24<1:27:03,  1.56it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 39/8192 [00:25<1:27:54,  1.55it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 40/8192 [00:25<1:28:19,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = []\n",
    "with open(base_file, 'r+') as f:\n",
    "    data = csv.DictReader(f)\n",
    "    data = [r for r in data]\n",
    "    pbar = tqdm(total=len(data))\n",
    "    for row in data:\n",
    "        prompt_list = ast.literal_eval(row[\"coarse-grained prompt\"])\n",
    "        prompt = prompt_list[1][\"prompt\"]\n",
    "        gpt2_ans = gpt2_pipe(prompt,do_sample=True,num_return_sequences=5,num_beams=10)\n",
    "        for i,_ in enumerate(gpt2_ans):\n",
    "            row[f\"ans_{i}\"] = _\n",
    "        output.append(row)\n",
    "        pbar.update(1)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4225e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./data/train_images_coarse-grained.csv.csv\", 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=output[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
